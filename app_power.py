"""
Q-Method (TADT Research) â€” Q Analyzer
@Author: Prof. Dr. Songhee Kang
@Date: 2025.08.14. 
- ì‚¬ëŒ ìš”ì¸í™”(Q): ì‘ë‹µì ê°„ ìƒê´€í–‰ë ¬ â†’ ê³ ìœ ë¶„í•´ â†’ Varimax íšŒì „ â†’ ìœ í˜•/ë°°ì •/ìƒí•˜ìœ„ ì§„ìˆ 
- CSVê°€ 'ì¡´ì¬í•˜ì§€ë§Œ ë¹„ì–´ìˆëŠ”' ê²½ìš° ì²« ì œì¶œë¡œ ê°™ì€ íŒŒì¼ì— ì±„ì›€
- ì œì¶œ ì‹œ GitHubì— ì¦‰ì‹œ ì»¤ë°‹(REST API, PyGithub ë¶ˆìš”)
- ì‚¬ì´ë“œë°”: ìë™ ë™ê¸°í™” í† ê¸€ / ì§€ê¸ˆ ë™ê¸°í™” ë²„íŠ¼ / ê´€ë¦¬ì ë‹¤ìš´ë¡œë“œ
"""

import os, re, base64, json, datetime
import numpy as np
import pandas as pd
import requests
import streamlit as st
import matplotlib.pyplot as plt

# -----------------------------
# Page & Globals
# -----------------------------
st.set_page_config(page_title="Q-Method (TADT Research) Analyzer", layout="wide")
st.title("Q-Method (TADT Research) Analyzer")

DATA_PATH = "responses_power1.csv"   # ë¡œì»¬ CSV ê²½ë¡œ
MIN_N_FOR_ANALYSIS = 5
TOPK_STATEMENTS = 5
EPS = 1e-8

# -----------------------------
# Optional font
# -----------------------------
try:
    import matplotlib.font_manager as fm
    font_path = "fonts/NanumGothic.ttf"
    if os.path.exists(font_path):
        plt.rcParams['font.family'] = fm.FontProperties(fname=font_path).get_name()
except Exception:
    pass

# -----------------------------
# Secrets (GitHub)
# -----------------------------
def _get_secret(path, default=""):
    try:
        cur = st.secrets
        for key in path.split("."):
            cur = cur[key]
        return cur
    except Exception:
        return default

GH_TOKEN   = _get_secret("github.token")
GH_REPO    = _get_secret("github.repo")
GH_BRANCH  = _get_secret("github.branch", "main")
GH_REMOTEP = _get_secret("github.data_path", "responses_power1.csv")  # ì›ê²© ì €ì¥ ê²½ë¡œ
GH_README  = _get_secret("github.readme_path", "README.md")         # (ì˜µì…˜)

# -----------------------------
# Admin (optional)
# -----------------------------
st.sidebar.subheader("ğŸ” ê´€ë¦¬ì / ë™ê¸°í™”")
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

admin_pw = st.sidebar.text_input("ê´€ë¦¬ì ë¹„ë°€ë²ˆí˜¸ (ì„ íƒ)", type="password")
if st.sidebar.button("ë¡œê·¸ì¸"):
    if admin_pw and _get_secret("admin.password") == admin_pw:
        st.session_state.authenticated = True
        st.sidebar.success("ì¸ì¦ ì„±ê³µ")
    else:
        st.sidebar.error("ì¸ì¦ ì‹¤íŒ¨")

auto_sync = st.sidebar.checkbox("ì‘ë‹µ ì €ì¥ ì‹œ GitHub ìë™ í‘¸ì‹œ", value=True)

def _gh_headers(token):
    return {
        "Authorization": f"token {token}",
        "Accept": "application/vnd.github+json",
        "X-GitHub-Api-Version": "2022-11-28",
        "Content-Type": "application/json",
        "User-Agent": "streamlit-qmethod-tadt"
    }

def gh_get_sha(owner_repo, path, token, branch):
    url = f"https://api.github.com/repos/{owner_repo}/contents/{path}"
    r = requests.get(url, headers=_gh_headers(token), params={"ref": branch}, timeout=20)
    if r.status_code == 200:
        try:
            return r.json().get("sha")
        except Exception:
            return None
    elif r.status_code == 404:
        return None
    else:
        raise RuntimeError(f"GitHub GET ì‹¤íŒ¨: {r.status_code} {r.text}")

def gh_put_file(owner_repo, path, token, branch, content_bytes, message):
    url = f"https://api.github.com/repos/{owner_repo}/contents/{path}"
    b64 = base64.b64encode(content_bytes).decode("ascii")
    sha = gh_get_sha(owner_repo, path, token, branch)
    payload = {"message": message, "content": b64, "branch": branch}
    if sha:
        payload["sha"] = sha
    r = requests.put(url, headers=_gh_headers(token), data=json.dumps(payload), timeout=30)
    if r.status_code in (200, 201):
        return True, r.json()
    return False, f"{r.status_code}: {r.text}"

def push_csv_to_github(local_path, remote_path=None, note="Update responses_tadt.csv"):
    if not (GH_TOKEN and GH_REPO):
        return False, "GitHub secrets ëˆ„ë½(github.token, github.repo)"
    if remote_path is None:
        remote_path = GH_REMOTEP
    try:
        with open(local_path, "rb") as f:
            content = f.read()
    except Exception as e:
        return False, f"ë¡œì»¬ CSV ì½ê¸° ì‹¤íŒ¨: {e}"
    ok, resp = gh_put_file(GH_REPO, remote_path, GH_TOKEN, GH_BRANCH, content, note)
    return ok, resp

# -----------------------------
# Utils
# -----------------------------
EMAIL_RE = re.compile(r"^[^@\s]+@[^@\s]+\.[^@\s]+$")

def is_valid_email(s: str) -> bool:
    if not s: return False
    s = s.strip()
    if len(s) > 150: return False
    return bool(EMAIL_RE.match(s))

def load_csv_safe(path: str):
    if not os.path.exists(path):
        return None
    try:
        if os.path.getsize(path) == 0:
            return None
        df = pd.read_csv(path)
        if df.empty:
            return None
        return df
    except Exception:
        return None

def save_csv_safe(df: pd.DataFrame, path: str):
    try:
        df.to_csv(path, index=False, encoding="utf-8-sig")
        return True
    except Exception as e:
        st.error(f"CSV ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def ensure_q_columns(df: pd.DataFrame, q_count: int):
    cols = [f"Q{i:02d}" for i in range(1, q_count + 1)]
    for c in cols:
        if c not in df.columns: df[c] = np.nan
    return df, cols

def zscore_rows(a: np.ndarray):
    m = a.mean(axis=1, keepdims=True)
    s = a.std(axis=1, ddof=0, keepdims=True)
    s = np.where(s < EPS, 1.0, s)
    return (a - m) / s

def rank_rows(a: np.ndarray):
    df = pd.DataFrame(a)
    return df.rank(axis=1, method="average", na_option="keep").values

def varimax(Phi, gamma=1.0, q=100, tol=1e-6, seed=42):
    Phi = Phi.copy(); p, k = Phi.shape
    R = np.eye(k); d_old = 0
    for _ in range(q):
        Lambda = Phi @ R
        u, s, vh = np.linalg.svd(
            Phi.T @ (Lambda**3 - (gamma/p) * (Lambda @ np.diag(np.sum(Lambda**2, axis=0))))
        )
        R = u @ vh
        d = np.sum(s)
        if d_old != 0 and d/d_old < 1 + tol: break
        d_old = d
    return Phi @ R, R

def choose_n_factors(eigvals, nmax):
    k = int(np.sum(eigvals >= 1.0))
    return max(2, min(nmax, k))


# -----------------------------
# Tabs
# -----------------------------
tab1, tab2 = st.tabs([ "ğŸ“Š ì‚¬ëŒ ìš”ì¸í™”(Q) ë¶„ì„", "â˜ï¸ GitHub ë™ê¸°í™” ë¡œê·¸"])
   
# -----------------------------
# Person-Q Analysis Helpers
# -----------------------------
def person_q_analysis(df_q: pd.DataFrame,
                      corr_metric: str = "Pearson",
                      n_factors: int | None = None,
                      rotate: bool = True):
    M = df_q.values.astype(float)
    if corr_metric.lower().startswith("spear"):
        M_proc = rank_rows(M)
        M_proc = zscore_rows(M_proc)
    else:
        M_proc = zscore_rows(M)

    R = np.corrcoef(M_proc, rowvar=True)
    R = np.nan_to_num(R, nan=0.0, posinf=0.0, neginf=0.0)

    eigvals, eigvecs = np.linalg.eigh(R)
    idx = np.argsort(eigvals)[::-1]
    eigvals = eigvals[idx]; eigvecs = eigvecs[:, idx]

    nmax = max(2, min(6, R.shape[0]-1))
    if n_factors is None or n_factors < 1:
        n_factors = choose_n_factors(eigvals, nmax)
    else:
        n_factors = max(2, min(nmax, int(n_factors)))

    L = eigvecs[:, :n_factors] * np.sqrt(np.maximum(eigvals[:n_factors], 0))
    L_rot = varimax(L)[0] if rotate else L

    arrays = []
    for k in range(n_factors):
        w = np.clip(L_rot[:, k], a_min=0.0, a_max=None)
        if w.sum() <= EPS: w = np.abs(L_rot[:, k])
        w = w / (w.sum() + EPS)
        arr_k = w @ M_proc
        arrays.append(arr_k)
    arrays = np.vstack(arrays)
    return L_rot, eigvals, R, arrays

def assign_types(loadings: np.ndarray, emails: list[str], thr: float = 0.40, sep: float = 0.10):
    N, K = loadings.shape
    max_idx = loadings.argmax(axis=1)
    max_val = loadings.max(axis=1)
    sorted_vals = np.sort(loadings, axis=1)[:, ::-1]
    second = sorted_vals[:,1] if K >= 2 else np.zeros(N)
    assigned = (max_val >= thr) & ((max_val - second) >= sep)
    rows = []
    for i in range(N):
        rows.append({
            "email": emails[i] if i < len(emails) else f"id_{i}",
            "Type": f"Type{max_idx[i]+1}",
            "MaxLoading": float(max_val[i]),
            "Second": float(second[i]),
            "Assigned": bool(assigned[i])
        })
    return pd.DataFrame(rows)

def top_bottom_statements(factor_arrays: np.ndarray, topk=5):
    K, P = factor_arrays.shape
    tb = []
    for k in range(K):
        z = factor_arrays[k]
        top_idx = np.argsort(z)[::-1][:topk]
        bot_idx = np.argsort(z)[:topk]
        tb.append((top_idx, bot_idx, z))
    return tb

# -----------------------------
# Tab2: Person-Q Analysis
# -----------------------------
with tab1:
    st.subheader("ì‚¬ëŒ ìš”ì¸í™”(Q) ë¶„ì„")
    df = load_csv_safe(DATA_PATH)
    if df is None:
        st.info("ì•„ì§ ìˆ˜ì§‘ëœ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤. (ë¹ˆ íŒŒì¼ì´ë©´ ë¨¼ì € ì„¤ë¬¸ ì œì¶œ)")
    else:
        df, _ = ensure_q_columns(df, q_count=len(Q_SET))
        df_q = df[Q_COLS].copy()
        mask = df_q.notna().sum(axis=1) >= int(0.6*len(Q_COLS))
        df_q = df_q[mask]
        emails = df.loc[mask, "email"].fillna("").astype(str).tolist()

        st.write(f"ìœ íš¨ ì‘ë‹µì ìˆ˜: **{len(df_q)}ëª…**")
        if len(df_q) < MIN_N_FOR_ANALYSIS:
            st.warning(f"ë¶„ì„ì—ëŠ” ìµœì†Œ {MIN_N_FOR_ANALYSIS}ëª…ì˜ ì‘ë‹µì´ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            with st.expander("âš™ï¸ ë¶„ì„ ì˜µì…˜", expanded=True):
                colA, colB, colC = st.columns(3)
                with colA:
                    corr_metric = st.selectbox("ìƒê´€ê³„ìˆ˜", ["Pearson", "Spearman"], index=0)
                with colB:
                    n_f_override = st.number_input("ìš”ì¸ ìˆ˜(ì„ íƒ, 0=ìë™)", min_value=0, max_value=6, value=0, step=1)
                    n_factors = None if n_f_override == 0 else int(n_f_override)
                with colC:
                    rotate = st.checkbox("Varimax íšŒì „", value=True)

                thr = st.slider("ìœ í˜• ë°°ì • ì„ê³„ê°’(ìµœëŒ€ ì ì¬ì¹˜)", 0.20, 0.70, 0.40, 0.05)
                sep = st.slider("1ë“±-2ë“± ì ì¬ì¹˜ ìµœì†Œ ê²©ì°¨", 0.00, 0.50, 0.10, 0.05)

            try:
                loadings, eigvals, R, arrays = person_q_analysis(df_q, corr_metric, n_factors, rotate)
                K = loadings.shape[1]

                st.markdown(f"**ì¶”ì¶œ ìš”ì¸ ìˆ˜: {K}**")
                load_df = pd.DataFrame(loadings, columns=[f"Type{i+1}" for i in range(K)])
                load_df.insert(0, "email", emails)
                st.dataframe(load_df.style.background_gradient(cmap="Blues", axis=None), use_container_width=True)

                assign_df = assign_types(loadings, emails, thr=thr, sep=sep)
                st.markdown("### ì°¸ê°€ì ìœ í˜• ë°°ì •")
                st.dataframe(assign_df, use_container_width=True)
                st.write("ìœ í˜•ë³„ ì¸ì›ìˆ˜:", assign_df[assign_df["Assigned"]].groupby("Type").size().to_dict())

                st.download_button(
                    "ğŸ“¥ ì°¸ê°€ì-ìœ í˜• ë°°ì • CSV",
                    data=assign_df.to_csv(index=False).encode("utf-8-sig"),
                    file_name="person_type_assignments.csv",
                    mime="text/csv"
                )

                arrays_df = pd.DataFrame(arrays, columns=Q_COLS, index=[f"Type{i+1}" for i in range(K)])
                st.markdown("### ìœ í˜•ë³„ factor array (ì§„ìˆ  z-í”„ë¡œíŒŒì¼)")
                st.dataframe(arrays_df, use_container_width=True)
                st.download_button(
                    "ğŸ“¥ ìœ í˜•ë³„ factor array CSV",
                    data=arrays_df.to_csv().encode("utf-8-sig"),
                    file_name="type_factor_arrays.csv",
                    mime="text/csv"
                )

                st.markdown(f"### ìœ í˜•ë³„ ìƒ/í•˜ìœ„ ì§„ìˆ  Top {TOPK_STATEMENTS}")
                tb = top_bottom_statements(arrays, topk=TOPK_STATEMENTS)
                for i, (top_idx, bot_idx, z) in enumerate(tb, start=1):
                    with st.expander(f"Type{i} ìƒ/í•˜ìœ„ ì§„ìˆ ", expanded=True if i==1 else False):
                        st.markdown("**ìƒìœ„(+) ì§„ìˆ **")
                        for j in top_idx:
                            st.write(f"- Q{j+1:02d} (z={z[j]:.2f}) : {Q_SET[j]}")
                        st.markdown("**í•˜ìœ„(âˆ’) ì§„ìˆ **")
                        for j in bot_idx:
                            st.write(f"- Q{j+1:02d} (z={z[j]:.2f}) : {Q_SET[j]}")

            except Exception as e:
                st.error(f"ì‚¬ëŒ ìš”ì¸í™” ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")

# -----------------------------
# Tab3: GitHub Sync Log / Manual Push
# -----------------------------
with tab2:
    st.subheader("GitHub ë™ê¸°í™”")
    if not (GH_TOKEN and GH_REPO):
        st.warning("Secretsì— github.token, github.repo ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        st.code("""
[github]
token = "ghp_..."
repo  = "owner/repo"
branch = "main"
data_path = "data/responses_tadt.csv"
        """, language="toml")
    else:
        st.success(f"ì›ê²©: {GH_REPO} @ {GH_BRANCH}\nê²½ë¡œ: {GH_REMOTEP}")

    if st.button("ì§€ê¸ˆ ë™ê¸°í™”(ìˆ˜ë™)"):
        if os.path.exists(DATA_PATH) and os.path.getsize(DATA_PATH) > 0:
            ok, resp = push_csv_to_github(DATA_PATH, GH_REMOTEP,
                                          note=f"Manual sync {GH_REMOTEP} at {datetime.datetime.now().isoformat()}")
            if ok:
                st.success("GitHubì— ë™ê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.json(resp)
            else:
                st.error(f"ë™ê¸°í™” ì‹¤íŒ¨: {resp}")
        else:
            st.error("ë¡œì»¬ CSVê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë¨¼ì € ì„¤ë¬¸ì„ ì œì¶œí•´ CSVë¥¼ ìƒì„±í•˜ì„¸ìš”.")
