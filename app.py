# Create a ready-to-run Streamlit app implementing Likert-based Q-Method (TADT) with strategy matrices.
# The file will be saved so the user can download it.

from textwrap import dedent

app_code = dedent(r'''
"""
Q-Method (TADT) Streamlit Application

Author      : Your Team
Last Update : 2025-08-14
Description : Likert-based Q-Method survey tool for TADT (Tech-Affective Dynamics Theory)
              - Optional domain scenarios (ê³ ê°ì„¼í„°/ì˜ë£Œ/êµìœ¡)
              - Likert (1~5) ratings for up to 30 statements (Q-set)
              - Factor analysis (with fallback to PCA) to derive types
              - Mapping types onto two strategy matrices:
                   (1) ì˜ˆì¸¡ vs ê³µê°
                   (2) ìœ„ì„ vs í˜‘ì—…
              - Auto-generate recommendations for ìš´ì˜ëª¨ë¸ / ì¸ì‚¬ì „ëµ / ì„œë¹„ìŠ¤ í˜ì‹ 
"""

import os
import datetime
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt

# Try to import FactorAnalyzer; if not available, fall back to sklearn PCA
_FA_AVAILABLE = True
try:
    from factor_analyzer import FactorAnalyzer
except Exception:
    _FA_AVAILABLE = False
    from sklearn.decomposition import PCA

# -----------------------------
# Page & Globals
# -----------------------------
st.set_page_config(page_title="Q-Method (TADT) Analyzer", layout="wide")
st.title("Q-Method (TADT) Likert Analyzer")

DATA_PATH = "responses_tadt.csv"

# -----------------------------
# Helper: Korean font (optional)
# -----------------------------
try:
    import matplotlib.font_manager as fm
    font_path = "fonts/NanumGothic.ttf"
    if os.path.exists(font_path):
        plt.rcParams['font.family'] = fm.FontProperties(fname=font_path).get_name()
except Exception:
    pass

# -----------------------------
# Sidebar: Admin
# -----------------------------
st.sidebar.subheader("ğŸ” ê´€ë¦¬ì ëª¨ë“œ")
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

admin_pw = st.sidebar.text_input("ê´€ë¦¬ì ë¹„ë°€ë²ˆí˜¸", type="password")
if st.sidebar.button("ë¡œê·¸ì¸"):
    if admin_pw and os.environ.get("ADMIN_PASSWORD", "") == admin_pw:
        st.session_state.authenticated = True
        st.sidebar.success("ì¸ì¦ ì„±ê³µ")
    else:
        st.sidebar.error("ì¸ì¦ ì‹¤íŒ¨")

if st.session_state.authenticated and os.path.exists(DATA_PATH):
    df_dl = pd.read_csv(DATA_PATH)
    st.sidebar.download_button(
        label="ğŸ“¥ ì‘ë‹µ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
        data=df_dl.to_csv(index=False).encode("utf-8-sig"),
        file_name="responses_tadt.csv",
        mime="text/csv",
    )

# -----------------------------
# Q-set (max 30)
# -----------------------------
Q_SET = [
    # A. ê°ì • ì „ëµ/ì–´ì¡°
    "ë™ì¼í•œ ì •í™•ë„ë¼ë©´, ê³µê°ì  ì–´ì¡°ëŠ” ì‚¬ìš©ì ì‹ ë¢°ë¥¼ ìœ ì˜í•˜ê²Œ ë†’ì¸ë‹¤.",                               # Q01
    "ê³µê° í‘œí˜„ì´ ê·¼ê±°(íŒ©íŠ¸Â·ì¶œì²˜) ì—†ì´ ë°˜ë³µë˜ë©´ ì‹ ë¢°ëŠ” ì˜¤íˆë ¤ ì €í•˜ëœë‹¤.",                              # Q02
    "ì¤‘ë¦½Â·ì •ë³´ ì¤‘ì‹¬ ì–´ì¡°ëŠ” ë‹¨ê¸° íš¨ìœ¨ì—ëŠ” ìœ ë¦¬í•˜ì§€ë§Œ ì¥ê¸° ê´€ê³„ ì‹ ë¢°ì—ëŠ” í•œê³„ê°€ ìˆë‹¤.",                   # Q03
    "ê°ì • í†¤ì˜ ì¼ê´€ì„±ì€ ì •í™•ì„±ì˜ ì¼ê´€ì„±ë§Œí¼ ì‹ ë¢° ì¶•ì ì— ì¤‘ìš”í•˜ë‹¤.",                                    # Q04
    # B. ë°˜ë³µ/ì‹œê°„ ë™ì—­í•™
    "ì‘ì€ ê¸°ëŒ€ ìœ„ë°˜ì´ ë°˜ë³µë˜ë©´ ì‹ ë¢°ëŠ” ë¹„ì„ í˜•ì ìœ¼ë¡œ ê¸‰ê²©íˆ ë¬´ë„ˆì§„ë‹¤.",                                  # Q05
    "ì˜¤ë¥˜ ì´í›„ ì‚¬ê³¼Â·ì„¤ëª…Â·ìˆ˜ì • ê³„íš ì œì‹œëŠ” ì‹ ë¢° íšŒë³µì„ ì´‰ì§„í•œë‹¤.",                                       # Q06
    "ê°œì¸ ë§¥ë½(ì´ë ¥Â·ì„ í˜¸)ì„ ê¸°ì–µí•˜ëŠ” AIëŠ” ë°˜ë³µ ìƒí˜¸ì‘ìš©ì—ì„œ ì‹ ë¢°ë¥¼ ë” ë¹¨ë¦¬ ì¶•ì í•œë‹¤.",                   # Q07
    "ëª¨ë¸ í•œê³„Â·ë¶ˆí™•ì‹¤ì„±ì˜ ëª…ì‹œëŠ” ê³¼ì‹ ì„ ì¤„ì´ê³  ì§€ì† ì‹ ë¢°ë¥¼ ë†’ì¸ë‹¤.",                                     # Q08
    # C. ì„¤ëª…ê°€ëŠ¥ì„±/í†µì œ
    "ì„¤ëª… ê°€ëŠ¥í•œ ê·¼ê±° ì œì‹œëŠ” ê³µê° í‘œí˜„ë³´ë‹¤ ë¬´ê²°ì„± ì‹ ë¢°ë¥¼ ë” ê°•í•˜ê²Œ ë§Œë“ ë‹¤.",                           # Q09
    "ì‚¬ìš©ìê°€ ì‘ë‹µ í†¤(ê³µê°/ì¤‘ë¦½)ì„ ì„ íƒÂ·ì¡°ì ˆí•  ìˆ˜ ìˆì„ ë•Œ ì‹ ë¢°ê°€ ë†’ì•„ì§„ë‹¤.",                             # Q10
    "ì‚¬ìš©ì í”¼ë“œë°±ì´ í•™ìŠµ ë£¨í”„ì— ë°˜ì˜ëœë‹¤ëŠ” ì‹ í˜¸ê°€ ìˆì„ ë•Œ ì¥ê¸° ì‹ ë¢°ê°€ ê°•í™”ëœë‹¤.",                       # Q11
    # D. ì¸ê°„í™”/ì˜ì¸í™”
    "ì ì • ìˆ˜ì¤€ì˜ ì¸ê°„í™” ë‹¨ì„œ(ì´ë¦„Â·ì¼ê´€ëœ í˜ë¥´ì†Œë‚˜)ëŠ” ì‹ ë¢° í˜•ì„±ì— ë„ì›€ì´ ëœë‹¤.",                        # Q12
    "ê³¼ë„í•œ ì¸ê°„í™”Â·ê°ì • ê³¼ì‹œëŠ” ì–¸ìºë‹ˆ íš¨ê³¼ë¡œ ì‹ ë¢°ë¥¼ ë–¨ì–´ëœ¨ë¦°ë‹¤.",                                       # Q13
    "â€˜ì‚¬ëŒì²˜ëŸ¼ ë³´ì´ëŠ”ê°€â€™ë³´ë‹¤ í˜ë¥´ì†Œë‚˜ì˜ ì¼ê´€ì„±ì´ ì‹ ë¢°ì— ë” ì¤‘ìš”í•˜ë‹¤.",                                   # Q14
    # E. ìœ„í—˜ë„/ë„ë©”ì¸ ì›ì¹™
    "ê³ ìœ„í—˜Â·ê³ ì±…ì„ ì˜ì—­ì—ì„œëŠ” Human-in-the-Loopê°€ ê¸°ë³¸ ì„¤ê³„ ì›ì¹™ì´ì–´ì•¼ í•œë‹¤.",                          # Q15
    "ì €ìœ„í—˜Â·ì •í˜• ì—…ë¬´ì—ì„œëŠ” AI ë‹¨ë… ìœ„ì„ì´ íš¨ìœ¨Â·í’ˆì§ˆ ëª¨ë‘ì—ì„œ íƒ€ë‹¹í•˜ë‹¤.",                                # Q16
    "ê³µê° ì¤‘ì‹¬ ì—…ë¬´ì—ì„œëŠ” ì¸ê°„â€“AI í˜‘ì—…ì´ ì¸ê°„ ë‹¨ë…Â·AI ë‹¨ë…ë³´ë‹¤ ì„±ê³¼ê°€ ë†’ë‹¤.",                           # Q17
    # F. ìš´ì˜ ëª¨ë¸/í”„ë¡œì„¸ìŠ¤
    "ëª…í™•í•œ ì—ìŠ¤ì»¬ë ˆì´ì…˜ ê·œì¹™(ëŒ€í™” ì¤‘ë‹¨â†’ì‚¬ëŒ ì—°ê²°)ì€ ì‚¬ìš©ì ì‹ ë¢°ë¥¼ ë³´í˜¸í•œë‹¤.",                          # Q18
    "ì‘ë‹µ SLAÂ·í’ˆì§ˆê³¼ ì •ì„œ ì í•©ì„±ì„ í•¨ê»˜ ì¸¡ì •í•  ë•Œ ì¡°ì§ ì‹ ë¢°ê°€ ìœ ì§€ëœë‹¤.",                               # Q19
    "ë°ì´í„° ìµœì†Œìˆ˜ì§‘Â·í”„ë¼ì´ë²„ì‹œ ë³´ì¥ì€ ê°ì • ë°ì´í„° í™œìš©ì˜ í•„ìˆ˜ ì‹ ë¢° ì¡°ê±´ì´ë‹¤.",                         # Q20
    "í¸í–¥Â·ê³µì •ì„± ì™„í™” ë…¸ë ¥ì˜ ê°€ì‹œí™”ëŠ” ë¬´ê²°ì„± ì‹ ë¢°ë¥¼ ê°•í™”í•œë‹¤.",                                         # Q21
    # G. ì¸ì‚¬/ì—­ëŸ‰/êµìœ¡
    "ì¡°ì§ì€ â€˜ì‘ì„±ìâ€™ë³´ë‹¤ ê²€ìˆ˜ì/íë ˆì´í„°/ìƒí™©ì¡°ì ˆì ì—­ëŸ‰ì„ ì¤‘ì‹œí•˜ë„ë¡ ì§ë¬´ë¥¼ ì¬ì„¤ê³„í•´ì•¼ í•œë‹¤.",           # Q22
    "ê³µê° ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ê³¼ AI ë¦¬í„°ëŸ¬ì‹œì˜ ë™ì‹œ í›ˆë ¨ì´ í˜‘ì—… ì„±ê³¼ë¥¼ ê·¹ëŒ€í™”í•œë‹¤.",                             # Q23
    "ë³´ìƒÂ·í‰ê°€ê°€ ì •í™•ì„±ë¿ ì•„ë‹ˆë¼ ì •ì„œ ì í•©ì„±ì„ ë°˜ì˜í•  ë•Œ ì±„íƒì´ ì´‰ì§„ëœë‹¤.",                              # Q24
    # H. ì„œë¹„ìŠ¤ í˜ì‹ /ì „ëµ ë§¤íŠ¸ë¦­ìŠ¤
    "ì˜ˆì¸¡ ì¤‘ì‹¬ ì§ë¬´êµ°ì€ â€˜ìœ„ì„ ì „ëµâ€™ì´ ê¸°ë³¸ ì›ì¹™ì´ì–´ì•¼ í•œë‹¤.",                                           # Q25
    "ê³µê° ì¤‘ì‹¬ ì§ë¬´êµ°ì€ â€˜í˜‘ì—… ì „ëµâ€™ì´ ê¸°ë³¸ ì›ì¹™ì´ì–´ì•¼ í•œë‹¤.",                                           # Q26
    "ê³ ê°ì„¼í„°ì—ì„œëŠ” AI ì´ˆì•ˆ+ì¸ê°„ ìµœì¢… ê²€ìˆ˜(í•˜ì´ë¸Œë¦¬ë“œ)ê°€ ë¹„ìš©ê³¼ ë§Œì¡±ë„ë¥¼ ë™ì‹œì— ê°œì„ í•œë‹¤.",               # Q27
    "ì˜ë£Œì—ì„œëŠ” ê³µê°í˜• ì´ˆì§„Â·ì„¤ëª… + ì˜ì‚¬ íŒë‹¨ ê²°í•©ì´ ì•ˆì „ì„±ê³¼ ì‹ ë¢°ë¥¼ ë³´ì¥í•œë‹¤.",                           # Q28
    "êµìœ¡ì—ì„œëŠ” AIì˜ ê°œë³„ í”¼ë“œë°± + êµì‚¬ì˜ ì •ì„œ ì½”ì¹­ì´ í•™ìŠµ ì§€ì†ì„±ì„ ë†’ì¸ë‹¤.",                            # Q29
    "ì‚¬ìš©ì ì„¸ë¶„í™”(ë„êµ¬ì§€í–¥/ê´€ê³„ì§€í–¥)ì— ë”°ë¼ í†¤ê³¼ ìë™í™” ìˆ˜ì¤€ì„ ì°¨ë“± ì œê³µí•´ì•¼ í•œë‹¤.",                    # Q30
]

# Statements tags for dimension mapping (weights: +1 or -1)
# Axes: Empathy vs Predictive, Delegation vs Collaboration
AXIS_WEIGHTS = {
    "Empathy": {
        "Q01": +1, "Q02": -1, "Q04": +1,
        "Q12": +1, "Q13": -1, "Q14": +1,
        "Q17": +1, "Q23": +1, "Q24": +1, "Q29": +1,
        "Q28": +1
    },
    "Predictive": {
        "Q03": +1, "Q09": +1, "Q10": +1, "Q11": +1,
        "Q16": +1, "Q25": +1, "Q27": +1,
        "Q15": -1  # HIL ì„ í˜¸ëŠ” ìˆœìˆ˜ ì˜ˆì¸¡/ìë™ ìœ„ì„ê³¼ ë°˜ëŒ€ ì‹ í˜¸ë¡œ ì²˜ë¦¬
    },
    "Delegation": {
        "Q16": +1, "Q25": +1, "Q27": +1,
        "Q15": -1, "Q17": -1, "Q26": -1, "Q28": -1, "Q29": -1
    },
    "Collaboration": {
        "Q15": +1, "Q17": +1, "Q18": +1, "Q19": +1,
        "Q26": +1, "Q28": +1, "Q29": +1,
        "Q16": -1, "Q25": -1
    },
}

# Optional domain scenarios
SCENARIOS = {
    "ê³ ê°ì„¼í„°": "ë‹¹ì‹ ì€ ê³ ê° ë¶ˆë§Œì„ ì²˜ë¦¬í•˜ëŠ” ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ë°˜ë³µì ìœ¼ë¡œ ë¹„ìŠ·í•œ ë¶ˆë§Œì„ ì ‘ìˆ˜í•˜ë©°, AI ë„ìš°ë¯¸ê°€ ì´ˆì•ˆì„ ì œì‹œí•©ë‹ˆë‹¤. "
               "AIì˜ ê°ì • í†¤(ê³µê°/ì¤‘ë¦½)ê³¼ ì„¤ëª…(ê·¼ê±°Â·ì‚¬ì‹¤)ì´ ì‹ ë¢°ì™€ íš¨ìœ¨ì— ì–´ë–¤ ì˜í–¥ì„ ì¤„ì§€ ìƒìƒí•´ ì£¼ì„¸ìš”.",
    "ì˜ë£Œ": "ë‹¹ì‹ ì€ í™˜ìì™€ ë³´í˜¸ìì—ê²Œ ê²€ì‚¬ ê²°ê³¼ë¥¼ ì„¤ëª…í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. AIê°€ ë¨¼ì € ì„¤ëª… ì´ˆì•ˆì„ ì œê³µí•˜ê³ , "
           "ë‹¹ì‹ ì´ ë³´ì™„Â·ê²°ì •í•©ë‹ˆë‹¤. ê³µê°ì  ì„¤ëª…ê³¼ ë¶ˆí™•ì‹¤ì„± ê³ ì§€ê°€ ì‹ ë¢°ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ê³ ë ¤í•´ ì£¼ì„¸ìš”.",
    "êµìœ¡": "ë‹¹ì‹ ì€ í•™ìŠµìì—ê²Œ í”¼ë“œë°±ì„ ì œê³µí•˜ëŠ” êµì‚¬ì…ë‹ˆë‹¤. AIê°€ ê°œë³„ í”¼ë“œë°±ì„ ì œì•ˆí•˜ê³ , "
           "ë‹¹ì‹ ì´ ì •ì„œ ì½”ì¹­ì„ ê²°í•©í•©ë‹ˆë‹¤. ë°˜ë³µ ìƒí˜¸ì‘ìš©ì—ì„œ ì‹ ë¢°ê°€ ì–´ë–»ê²Œ ë³€í• ì§€ ìƒìƒí•´ ì£¼ì„¸ìš”.",
}

LIKERT = ["ì „í˜€ ë™ì˜í•˜ì§€ ì•ŠìŒ(1)", "ë™ì˜í•˜ì§€ ì•ŠìŒ(2)", "ë³´í†µ(3)", "ë™ì˜í•¨(4)", "ë§¤ìš° ë™ì˜í•¨(5)"]
LIKERT_MAP = {
    "ì „í˜€ ë™ì˜í•˜ì§€ ì•ŠìŒ(1)": 1,
    "ë™ì˜í•˜ì§€ ì•ŠìŒ(2)": 2,
    "ë³´í†µ(3)": 3,
    "ë™ì˜í•¨(4)": 4,
    "ë§¤ìš° ë™ì˜í•¨(5)": 5
}

# -----------------------------
# Survey Tab
# -----------------------------
tab1, tab2, tab3 = st.tabs(["âœï¸ ì„¤ë¬¸ ì‘ë‹µ", "ğŸ“Š ìœ í˜•/ì „ëµ ë§¤í•‘", "ğŸ§  ê²°ê³¼ ìš”ì•½ ë° ê¶Œê³ "])

with tab1:
    st.subheader("âœï¸ Q-Method Likert ì„¤ë¬¸ (ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒì€ ì„ íƒ ì‚¬í•­)")
    colA, colB = st.columns([1,1])
    with colA:
        show_scenario = st.checkbox("ë„ë©”ì¸ ì‹œë‚˜ë¦¬ì˜¤ ë³´ê¸°", value=True)
        domain = st.selectbox("ë„ë©”ì¸ ì„ íƒ", list(SCENARIOS.keys()), index=0)
        if show_scenario:
            st.info(SCENARIOS[domain])
    with colB:
        pid = st.text_input("ì‘ë‹µì ID ë˜ëŠ” ì´ë©”ì¼(ì„ íƒ)", placeholder="ìµëª… ê°€ëŠ¥")

    with st.form("likert_form"):
        answers = {}
        for i, stmt in enumerate(Q_SET, start=1):
            qid = f"Q{i:02d}"
            sel = st.radio(f"{i}. {stmt}", LIKERT, horizontal=False, key=f"r_{qid}")
            answers[qid] = LIKERT_MAP[sel]
        submitted = st.form_submit_button("ì œì¶œ")

    if submitted:
        row = {**answers, "domain": domain, "pid": pid, "ts": datetime.datetime.now().isoformat()}
        if os.path.exists(DATA_PATH):
            df_old = pd.read_csv(DATA_PATH)
            df_all = pd.concat([df_old, pd.DataFrame([row])], ignore_index=True)
        else:
            df_all = pd.DataFrame([row])
        df_all.to_csv(DATA_PATH, index=False, encoding="utf-8-sig")
        st.success("ì‘ë‹µì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")

# -----------------------------
# Analysis Helpers
# -----------------------------
def _eigen_k(df_numeric):
    """Compute number of factors by Kaiser (eig >= 1)."""
    # Correlation matrix eigenvalues
    corr = np.corrcoef(df_numeric.T)
    eigvals = np.linalg.eigvalsh(corr)
    return int(np.sum(eigvals >= 1.0)), eigvals[::-1]

def factor_or_pca(df_numeric, n_factors=None):
    """Fit FactorAnalyzer (if available) else PCA; return loadings DataFrame and model name."""
    cols = df_numeric.columns
    if n_factors is None or n_factors < 1:
        k, _ = _eigen_k(df_numeric)
        n_factors = max(2, min(5, k))  # clamp 2..5 for interpretability

    if _FA_AVAILABLE:
        fa = FactorAnalyzer(n_factors=n_factors, rotation="varimax")
        fa.fit(df_numeric)
        load = pd.DataFrame(fa.loadings_, index=cols, columns=[f"Type{i+1}" for i in range(n_factors)])
        return load, "FA", n_factors
    else:
        pca = PCA(n_components=n_factors)
        comps = pca.fit_transform(df_numeric)  # scores (n_samples x n_factors) [unused]
        # construct pseudo-loadings from components_ (n_factors x n_features)
        load = pd.DataFrame(pca.components_.T, index=cols, columns=[f"Type{i+1}" for i in range(n_factors)])
        return load, "PCA", n_factors

def axis_scores_from_loadings(loadings: pd.DataFrame, axis_weights: dict) -> pd.DataFrame:
    """Compute axis scores (Empathy, Predictive, Delegation, Collaboration) per Type using statement loadings."""
    out = []
    for type_col in loadings.columns:
        row = {"Type": type_col}
        for axis, weights in axis_weights.items():
            num = 0.0
            den = 0.0
            for qid, w in weights.items():
                if qid in loadings.index:
                    num += loadings.loc[qid, type_col] * w
                    den += abs(w)
            row[axis] = num / den if den > 0 else 0.0
        out.append(row)
    return pd.DataFrame(out).set_index("Type")

def plot_strategy_scatter(df_axes: pd.DataFrame, x, y, title):
    fig, ax = plt.subplots()
    ax.axhline(0, ls="--", lw=1)
    ax.axvline(0, ls="--", lw=1)
    ax.scatter(df_axes[x], df_axes[y])
    for label, xy in df_axes[[x, y]].iterrows():
        ax.annotate(label, (xy[x], xy[y]), xytext=(5,5), textcoords="offset points")
    ax.set_xlabel(x)
    ax.set_ylabel(y)
    ax.set_title(title)
    st.pyplot(fig)

def recommendations_for_type(emp, pred, delg, coll):
    recs = []
    # ì˜ˆì¸¡ vs ê³µê°
    if pred >= 0.2 and coll <= 0 and delg >= 0.2:
        recs.append("ì „ëµ: **ìœ„ì„ ìš°ì„  (Predictive/Delegation High)** â€” ì €ìœ„í—˜Â·ì •í˜• ì—…ë¬´ ìë™í™”, ì¸ê°„ ê²€ìˆ˜ ìµœì†Œí™”")
        recs.append("ìš´ì˜ëª¨ë¸: ìë™ ë¼ìš°íŒ…Â·ìë™ì‘ë‹µ, ì˜ˆì™¸ì‹œ ì—ìŠ¤ì»¬ë ˆì´ì…˜")
        recs.append("ì¸ì‚¬ì „ëµ: ë°ì´í„°Â·í”„ë¡œì„¸ìŠ¤ ì„¤ê³„ ì—­ëŸ‰ ê°•í™”, ëª¨ë‹ˆí„°ë§/í’ˆì§ˆê´€ë¦¬ ì§ë¬´ ìœ¡ì„±")
        recs.append("ì„œë¹„ìŠ¤ í˜ì‹ : ì…€í”„ì„œë¹„ìŠ¤Â·FAQ ìë™í™”, ì´ˆì•ˆ ìë™ ìƒì„± íŒŒì´í”„ë¼ì¸")
    if coll >= 0.2 and emp >= 0.2:
        recs.append("ì „ëµ: **í˜‘ì—… ìš°ì„  (Empathy/Collaboration High)** â€” HILÂ·Co-pilot ì¤‘ì‹¬ ìš´ì˜")
        recs.append("ìš´ì˜ëª¨ë¸: ê³µê°í˜• ì´ˆì•ˆ + ì¸ê°„ ìµœì¢…, ì •ì„œ ì í•©ì„± KPI ë„ì…, ëª…í™•í•œ ì—ìŠ¤ì»¬ë ˆì´ì…˜")
        recs.append("ì¸ì‚¬ì „ëµ: ê³µê° ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ + AI ë¦¬í„°ëŸ¬ì‹œ ë™ì‹œ í›ˆë ¨, íë ˆì´ì…˜Â·ì„¤ëª… ì—­ëŸ‰ ê°•í™”")
        recs.append("ì„œë¹„ìŠ¤ í˜ì‹ : ê³ ê°ì„¼í„°/ì˜ë£Œ/êµìœ¡ í•˜ì´ë¸Œë¦¬ë“œ ë¸”ë£¨í”„ë¦°íŠ¸(ì´ˆì•ˆâ†’ê²€ìˆ˜â†’ì„¤ëª…)")
    if (pred > emp) and (coll > delg):
        recs.append("í˜¼í•© ì „ëµ: **ì„±ëŠ¥ì€ ì˜ˆì¸¡ ì§€í–¥, ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì€ í˜‘ì—…í˜•** â€” ëª¨ë¸ ì„¤ëª…/ê·¼ê±° ì œê³µê³¼ ì¸ê°„ ì¡°ì • ê²°í•©")
    if (emp > pred) and (delg > coll):
        recs.append("ì£¼ì˜: **ê°ì • ì˜ì¡´ + ìœ„ì„** ì¡°í•©ì€ ìœ„í—˜ â€” ê³µê° ì˜¤ì‘ë™ ì‹œ ì‹ ë¢° ë¶•ê´´. HIL ê°•í™” í•„ìš”")
    if not recs:
        recs.append("ì¤‘ë¦½ ì „ëµ: ë„ë©”ì¸Â·ë¦¬ìŠ¤í¬ì— ë”°ë¼ ìœ„ì„/í˜‘ì—… í˜¼í•©. HIL ìŠ¤ìœ„ì¹˜ì™€ í’ˆì§ˆ/ì •ì„œ KPI ë™ì‹œ ìš´ì˜")
    return recs

# -----------------------------
# Analysis Tab
# -----------------------------
with tab2:
    st.subheader("ğŸ“Š ìœ í˜• ë„ì¶œ(Q) ë° ì „ëµ ë§¤í•‘")
    if os.path.exists(DATA_PATH):
        df = pd.read_csv(DATA_PATH)
        # keep only Q columns
        qcols = [c for c in df.columns if c.startswith("Q")]
        if len(df) >= 5:
            df_num = df[qcols].copy()
            # small noise to avoid singularities
            df_num = df_num + np.random.normal(0, 1e-3, df_num.shape)
            # z-score standardize
            df_num = (df_num - df_num.mean()) / (df_num.std(ddof=0) + 1e-8)

            # Factor/PCA
            loadings, method_name, k = factor_or_pca(df_num)
            st.write(f"ë¶„ì„ ë°©ì‹: **{method_name}**, ì¶”ì¶œëœ ìœ í˜• ìˆ˜: **{k}**")
            st.dataframe(loadings.style.background_gradient(cmap='Blues', axis=None))

            # Axis scores per Type
            axes_df = axis_scores_from_loadings(loadings, AXIS_WEIGHTS)
            st.markdown("### ğŸ“ ìœ í˜•ë³„ ì¶• ì ìˆ˜ (ì •ê·œí™” ì „)")
            st.dataframe(axes_df)

            # Normalize axes to -1..1 (optional)
            axes_norm = axes_df.copy()
            for c in axes_norm.columns:
                vmax = max(1e-6, axes_norm[c].abs().max())
                axes_norm[c] = axes_norm[c] / vmax
            st.markdown("### ğŸ“ ìœ í˜•ë³„ ì¶• ì ìˆ˜ (ì •ê·œí™”, -1..1)")
            st.dataframe(axes_norm)

            # Plots
            st.markdown("#### ì „ëµ ë§¤íŠ¸ë¦­ìŠ¤ 1: ì˜ˆì¸¡ vs ê³µê°")
            plot_strategy_scatter(axes_norm, "Predictive", "Empathy", "ì˜ˆì¸¡(Predictive) vs ê³µê°(Empathy)")
            st.markdown("#### ì „ëµ ë§¤íŠ¸ë¦­ìŠ¤ 2: ìœ„ì„ vs í˜‘ì—…")
            plot_strategy_scatter(axes_norm, "Delegation", "Collaboration", "ìœ„ì„(Delegation) vs í˜‘ì—…(Collaboration)")

            # Download
            st.download_button(
                "ğŸ“¥ ìœ í˜•-ì¶• ì ìˆ˜ ë‹¤ìš´ë¡œë“œ (CSV)",
                data=axes_norm.to_csv().encode("utf-8-sig"),
                file_name="type_axis_scores.csv",
                mime="text/csv"
            )

            st.markdown("---")
            st.markdown("### ğŸ§­ ìœ í˜•ë³„ ê¶Œê³ ì•ˆ (ìš´ì˜ëª¨ë¸ / ì¸ì‚¬ì „ëµ / ì„œë¹„ìŠ¤ í˜ì‹ )")
            rec_rows = []
            for t, r in axes_norm.iterrows():
                recs = recommendations_for_type(
                    emp=r["Empathy"], pred=r["Predictive"],
                    delg=r["Delegation"], coll=r["Collaboration"]
                )
                st.markdown(f"**{t}**")
                for bullet in recs:
                    st.markdown(f"- {bullet}")
                rec_rows.append({
                    "Type": t,
                    "Empathy": r["Empathy"],
                    "Predictive": r["Predictive"],
                    "Delegation": r["Delegation"],
                    "Collaboration": r["Collaboration"],
                    "Recommendations": " | ".join(recs)
                })
            rec_df = pd.DataFrame(rec_rows)
            st.download_button(
                "ğŸ“¥ ìœ í˜•ë³„ ê¶Œê³ ì•ˆ ë‹¤ìš´ë¡œë“œ (CSV)",
                data=rec_df.to_csv(index=False).encode("utf-8-sig"),
                file_name="type_recommendations.csv",
                mime="text/csv"
            )
        else:
            st.warning("ë¶„ì„ì—ëŠ” ìµœì†Œ 5ëª…ì˜ ì‘ë‹µì´ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        st.info("ì•„ì§ ìˆ˜ì§‘ëœ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤. ì„¤ë¬¸ íƒ­ì—ì„œ ë¨¼ì € ì‘ë‹µì„ ìˆ˜ì§‘í•˜ì„¸ìš”.")

# -----------------------------
# Summary Tab
# -----------------------------
with tab3:
    st.subheader("ğŸ§  ê²°ê³¼ ìš”ì•½ ë° í™œìš© ê°€ì´ë“œ")
    st.markdown("""
    - ë³¸ ë„êµ¬ëŠ” Q-methodë¥¼ **ê°•ì œë¶„í¬ ëŒ€ì‹  Likert**ë¡œ ìˆ˜ì§‘í•˜ê³ , ìš”ì¸ë¶„ì„/PC ë¶„ì„ì„ í†µí•´ **ì¸ì‹ ìœ í˜•(Type)**ì„ ë„ì¶œí•©ë‹ˆë‹¤.
    - ìœ í˜•ë³„ ì¶• ì ìˆ˜(ì˜ˆì¸¡/ê³µê°/ìœ„ì„/í˜‘ì—…)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‘ ê°œì˜ **ì „ëµ ë§¤íŠ¸ë¦­ìŠ¤**ì— ë§¤í•‘í•©ë‹ˆë‹¤.
    - ê° ìœ í˜•ì— ëŒ€í•´ **ìš´ì˜ëª¨ë¸(ì—ìŠ¤ì»¬ë ˆì´ì…˜Â·KPIÂ·HIL), ì¸ì‚¬ì „ëµ(ì—­ëŸ‰Â·êµìœ¡Â·ë³´ìƒ), ì„œë¹„ìŠ¤ í˜ì‹ (í•˜ì´ë¸Œë¦¬ë“œ ë¸”ë£¨í”„ë¦°íŠ¸)** ê¶Œê³ ì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤.
    - ì‹œë‚˜ë¦¬ì˜¤ëŠ” ì„ íƒ ì‚¬í•­ì´ë©°, ë™ì¼ Q-setë§Œìœ¼ë¡œë„ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    """)
''')
