"""
Q-Method (TADT) â€” Person-Centred (Q) Analyzer + GitHub Auto Push

- ì‚¬ëŒ ìš”ì¸í™”(Q): ì‘ë‹µì ê°„ ìƒê´€í–‰ë ¬ â†’ ê³ ìœ ë¶„í•´ â†’ Varimax íšŒì „ â†’ ìœ í˜•/ë°°ì •/ìƒí•˜ìœ„ ì§„ìˆ 
- CSVê°€ 'ì¡´ì¬í•˜ì§€ë§Œ ë¹„ì–´ìˆëŠ”' ê²½ìš° ì²« ì œì¶œë¡œ ê°™ì€ íŒŒì¼ì— ì±„ì›€
- ì œì¶œ ì‹œ GitHubì— ì¦‰ì‹œ ì»¤ë°‹(REST API, PyGithub ë¶ˆìš”)
- ì‚¬ì´ë“œë°”: ìë™ ë™ê¸°í™” í† ê¸€ / ì§€ê¸ˆ ë™ê¸°í™” ë²„íŠ¼ / ê´€ë¦¬ì ë‹¤ìš´ë¡œë“œ

Secrets(.streamlit/secrets.toml):
[github]
token = "ghp_..."         # repo ë˜ëŠ” public_repo scope
repo = "owner/repo"
branch = "main"
data_path = "data/responses_tadt.csv"
readme_path = "README.md"  # (ì˜µì…˜)

[admin]
password = "secret123"     # (ì˜µì…˜)
"""

import os, re, base64, json, datetime
import numpy as np
import pandas as pd
import requests
import streamlit as st
import matplotlib.pyplot as plt

# -----------------------------
# Page & Globals
# -----------------------------
st.set_page_config(page_title="Q-Method (TADT) â€” Person Q + GitHub", layout="wide")
st.title("Q-Method (TADT) â€” ì‚¬ëŒ ìš”ì¸í™”(Q) + GitHub ë™ê¸°í™”")

DATA_PATH = "responses_tadt.csv"   # ë¡œì»¬ CSV ê²½ë¡œ
MIN_N_FOR_ANALYSIS = 5
TOPK_STATEMENTS = 5
EPS = 1e-8

# -----------------------------
# Optional font
# -----------------------------
try:
    import matplotlib.font_manager as fm
    font_path = "fonts/NanumGothic.ttf"
    if os.path.exists(font_path):
        plt.rcParams['font.family'] = fm.FontProperties(fname=font_path).get_name()
except Exception:
    pass

# -----------------------------
# Secrets (GitHub)
# -----------------------------
def _get_secret(path, default=""):
    try:
        cur = st.secrets
        for key in path.split("."):
            cur = cur[key]
        return cur
    except Exception:
        return default

GH_TOKEN   = _get_secret("github.token")
GH_REPO    = _get_secret("github.repo")
GH_BRANCH  = _get_secret("github.branch", "main")
GH_REMOTEP = _get_secret("github.data_path", "responses_tadt.csv")  # ì›ê²© ì €ì¥ ê²½ë¡œ
GH_README  = _get_secret("github.readme_path", "README.md")         # (ì˜µì…˜)

# -----------------------------
# Admin (optional)
# -----------------------------
st.sidebar.subheader("ğŸ” ê´€ë¦¬ì / ë™ê¸°í™”")
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

admin_pw = st.sidebar.text_input("ê´€ë¦¬ì ë¹„ë°€ë²ˆí˜¸ (ì„ íƒ)", type="password")
if st.sidebar.button("ë¡œê·¸ì¸"):
    if admin_pw and _get_secret("admin.password") == admin_pw:
        st.session_state.authenticated = True
        st.sidebar.success("ì¸ì¦ ì„±ê³µ")
    else:
        st.sidebar.error("ì¸ì¦ ì‹¤íŒ¨")

auto_sync = st.sidebar.checkbox("ì‘ë‹µ ì €ì¥ ì‹œ GitHub ìë™ í‘¸ì‹œ", value=True)

def _gh_headers(token):
    return {
        "Authorization": f"token {token}",
        "Accept": "application/vnd.github+json",
        "X-GitHub-Api-Version": "2022-11-28",
        "Content-Type": "application/json",
        "User-Agent": "streamlit-qmethod-tadt"
    }

def gh_get_sha(owner_repo, path, token, branch):
    url = f"https://api.github.com/repos/{owner_repo}/contents/{path}"
    r = requests.get(url, headers=_gh_headers(token), params={"ref": branch}, timeout=20)
    if r.status_code == 200:
        try:
            return r.json().get("sha")
        except Exception:
            return None
    elif r.status_code == 404:
        return None
    else:
        raise RuntimeError(f"GitHub GET ì‹¤íŒ¨: {r.status_code} {r.text}")

def gh_put_file(owner_repo, path, token, branch, content_bytes, message):
    url = f"https://api.github.com/repos/{owner_repo}/contents/{path}"
    b64 = base64.b64encode(content_bytes).decode("ascii")
    sha = gh_get_sha(owner_repo, path, token, branch)
    payload = {"message": message, "content": b64, "branch": branch}
    if sha:
        payload["sha"] = sha
    r = requests.put(url, headers=_gh_headers(token), data=json.dumps(payload), timeout=30)
    if r.status_code in (200, 201):
        return True, r.json()
    return False, f"{r.status_code}: {r.text}"

def push_csv_to_github(local_path, remote_path=None, note="Update responses_tadt.csv"):
    if not (GH_TOKEN and GH_REPO):
        return False, "GitHub secrets ëˆ„ë½(github.token, github.repo)"
    if remote_path is None:
        remote_path = GH_REMOTEP
    try:
        with open(local_path, "rb") as f:
            content = f.read()
    except Exception as e:
        return False, f"ë¡œì»¬ CSV ì½ê¸° ì‹¤íŒ¨: {e}"
    ok, resp = gh_put_file(GH_REPO, remote_path, GH_TOKEN, GH_BRANCH, content, note)
    return ok, resp

# -----------------------------
# Utils
# -----------------------------
EMAIL_RE = re.compile(r"^[^@\s]+@[^@\s]+\.[^@\s]+$")

def is_valid_email(s: str) -> bool:
    if not s: return False
    s = s.strip()
    if len(s) > 150: return False
    return bool(EMAIL_RE.match(s))

def load_csv_safe(path: str):
    if not os.path.exists(path):
        return None
    try:
        if os.path.getsize(path) == 0:
            return None
        df = pd.read_csv(path)
        if df.empty:
            return None
        return df
    except Exception:
        return None

def save_csv_safe(df: pd.DataFrame, path: str):
    try:
        df.to_csv(path, index=False, encoding="utf-8-sig")
        return True
    except Exception as e:
        st.error(f"CSV ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def ensure_q_columns(df: pd.DataFrame, q_count: int):
    cols = [f"Q{i:02d}" for i in range(1, q_count + 1)]
    for c in cols:
        if c not in df.columns: df[c] = np.nan
    return df, cols

def zscore_rows(a: np.ndarray):
    m = a.mean(axis=1, keepdims=True)
    s = a.std(axis=1, ddof=0, keepdims=True)
    s = np.where(s < EPS, 1.0, s)
    return (a - m) / s

def rank_rows(a: np.ndarray):
    df = pd.DataFrame(a)
    return df.rank(axis=1, method="average", na_option="keep").values

def varimax(Phi, gamma=1.0, q=100, tol=1e-6, seed=42):
    Phi = Phi.copy(); p, k = Phi.shape
    R = np.eye(k); d_old = 0
    for _ in range(q):
        Lambda = Phi @ R
        u, s, vh = np.linalg.svd(
            Phi.T @ (Lambda**3 - (gamma/p) * (Lambda @ np.diag(np.sum(Lambda**2, axis=0))))
        )
        R = u @ vh
        d = np.sum(s)
        if d_old != 0 and d/d_old < 1 + tol: break
        d_old = d
    return Phi @ R, R

def choose_n_factors(eigvals, nmax):
    k = int(np.sum(eigvals >= 1.0))
    return max(2, min(nmax, k))

# -----------------------------
# Q-set
# -----------------------------
Q_SET = [
    "ë™ì¼í•œ ì •í™•ë„ë¼ë©´, ê³µê°ì  ì–´ì¡°ëŠ” ì‚¬ìš©ì ì‹ ë¢°ë¥¼ ìœ ì˜í•˜ê²Œ ë†’ì¸ë‹¤.",
    "ê³µê° í‘œí˜„ì´ ê·¼ê±°(íŒ©íŠ¸Â·ì¶œì²˜) ì—†ì´ ë°˜ë³µë˜ë©´ ì‹ ë¢°ëŠ” ì˜¤íˆë ¤ ì €í•˜ëœë‹¤.",
    "ì¤‘ë¦½Â·ì •ë³´ ì¤‘ì‹¬ ì–´ì¡°ëŠ” ë‹¨ê¸° íš¨ìœ¨ì—ëŠ” ìœ ë¦¬í•˜ì§€ë§Œ ì¥ê¸° ê´€ê³„ ì‹ ë¢°ì—ëŠ” í•œê³„ê°€ ìˆë‹¤.",
    "ê°ì • í†¤ì˜ ì¼ê´€ì„±ì€ ì •í™•ì„±ì˜ ì¼ê´€ì„±ë§Œí¼ ì‹ ë¢° ì¶•ì ì— ì¤‘ìš”í•˜ë‹¤.",
    "ì‘ì€ ê¸°ëŒ€ ìœ„ë°˜ì´ ë°˜ë³µë˜ë©´ ì‹ ë¢°ëŠ” ë¹„ì„ í˜•ì ìœ¼ë¡œ ê¸‰ê²©íˆ ë¬´ë„ˆì§„ë‹¤.",
    "ì˜¤ë¥˜ ì´í›„ ì‚¬ê³¼Â·ì„¤ëª…Â·ìˆ˜ì • ê³„íš ì œì‹œëŠ” ì‹ ë¢° íšŒë³µì„ ì´‰ì§„í•œë‹¤.",
    "ê°œì¸ ë§¥ë½(ì´ë ¥Â·ì„ í˜¸)ì„ ê¸°ì–µí•˜ëŠ” AIëŠ” ë°˜ë³µ ìƒí˜¸ì‘ìš©ì—ì„œ ì‹ ë¢°ë¥¼ ë” ë¹¨ë¦¬ ì¶•ì í•œë‹¤.",
    "ëª¨ë¸ í•œê³„Â·ë¶ˆí™•ì‹¤ì„±ì˜ ëª…ì‹œëŠ” ê³¼ì‹ ì„ ì¤„ì´ê³  ì§€ì† ì‹ ë¢°ë¥¼ ë†’ì¸ë‹¤.",
    "ì„¤ëª… ê°€ëŠ¥í•œ ê·¼ê±° ì œì‹œëŠ” ê³µê° í‘œí˜„ë³´ë‹¤ ë¬´ê²°ì„± ì‹ ë¢°ë¥¼ ë” ê°•í•˜ê²Œ ë§Œë“ ë‹¤.",
    "ì‚¬ìš©ìê°€ ì‘ë‹µ í†¤(ê³µê°/ì¤‘ë¦½)ì„ ì„ íƒÂ·ì¡°ì ˆí•  ìˆ˜ ìˆì„ ë•Œ ì‹ ë¢°ê°€ ë†’ì•„ì§„ë‹¤.",
    "ì‚¬ìš©ì í”¼ë“œë°±ì´ í•™ìŠµ ë£¨í”„ì— ë°˜ì˜ëœë‹¤ëŠ” ì‹ í˜¸ê°€ ìˆì„ ë•Œ ì¥ê¸° ì‹ ë¢°ê°€ ê°•í™”ëœë‹¤.",
    "ì ì • ìˆ˜ì¤€ì˜ ì¸ê°„í™” ë‹¨ì„œ(ì´ë¦„Â·ì¼ê´€ëœ í˜ë¥´ì†Œë‚˜)ëŠ” ì‹ ë¢° í˜•ì„±ì— ë„ì›€ì´ ëœë‹¤.",
    "ê³¼ë„í•œ ì¸ê°„í™”Â·ê°ì • ê³¼ì‹œëŠ” ì–¸ìºë‹ˆ íš¨ê³¼ë¡œ ì‹ ë¢°ë¥¼ ë–¨ì–´ëœ¨ë¦°ë‹¤.",
    "â€˜ì‚¬ëŒì²˜ëŸ¼ ë³´ì´ëŠ”ê°€â€™ë³´ë‹¤ í˜ë¥´ì†Œë‚˜ì˜ ì¼ê´€ì„±ì´ ì‹ ë¢°ì— ë” ì¤‘ìš”í•˜ë‹¤.",
    "ê³ ìœ„í—˜Â·ê³ ì±…ì„ ì˜ì—­ì—ì„œëŠ” Human-in-the-Loopê°€ ê¸°ë³¸ ì„¤ê³„ ì›ì¹™ì´ì–´ì•¼ í•œë‹¤.",
    "ì €ìœ„í—˜Â·ì •í˜• ì—…ë¬´ì—ì„œëŠ” AI ë‹¨ë… ìœ„ì„ì´ íš¨ìœ¨Â·í’ˆì§ˆ ëª¨ë‘ì—ì„œ íƒ€ë‹¹í•˜ë‹¤.",
    "ê³µê° ì¤‘ì‹¬ ì—…ë¬´ì—ì„œëŠ” ì¸ê°„â€“AI í˜‘ì—…ì´ ì¸ê°„ ë‹¨ë…Â·AI ë‹¨ë…ë³´ë‹¤ ì„±ê³¼ê°€ ë†’ë‹¤.",
    "ëª…í™•í•œ ì—ìŠ¤ì»¬ë ˆì´ì…˜ ê·œì¹™(ëŒ€í™” ì¤‘ë‹¨â†’ì‚¬ëŒ ì—°ê²°)ì€ ì‚¬ìš©ì ì‹ ë¢°ë¥¼ ë³´í˜¸í•œë‹¤.",
    "ì‘ë‹µ SLAÂ·í’ˆì§ˆê³¼ ì •ì„œ ì í•©ì„±ì„ í•¨ê»˜ ì¸¡ì •í•  ë•Œ ì¡°ì§ ì‹ ë¢°ê°€ ìœ ì§€ëœë‹¤.",
    "ë°ì´í„° ìµœì†Œìˆ˜ì§‘Â·í”„ë¼ì´ë²„ì‹œ ë³´ì¥ì€ ê°ì • ë°ì´í„° í™œìš©ì˜ í•„ìˆ˜ ì‹ ë¢° ì¡°ê±´ì´ë‹¤.",
    "í¸í–¥Â·ê³µì •ì„± ì™„í™” ë…¸ë ¥ì˜ ê°€ì‹œí™”ëŠ” ë¬´ê²°ì„± ì‹ ë¢°ë¥¼ ê°•í™”í•œë‹¤.",
    "ì¡°ì§ì€ â€˜ì‘ì„±ìâ€™ë³´ë‹¤ ê²€ìˆ˜ì/íë ˆì´í„°/ìƒí™©ì¡°ì ˆì ì—­ëŸ‰ì„ ì¤‘ì‹œí•˜ë„ë¡ ì§ë¬´ë¥¼ ì¬ì„¤ê³„í•´ì•¼ í•œë‹¤.",
    "ê³µê° ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ê³¼ AI ë¦¬í„°ëŸ¬ì‹œì˜ ë™ì‹œ í›ˆë ¨ì´ í˜‘ì—… ì„±ê³¼ë¥¼ ê·¹ëŒ€í™”í•œë‹¤.",
    "ë³´ìƒÂ·í‰ê°€ê°€ ì •í™•ì„±ë¿ ì•„ë‹ˆë¼ ì •ì„œ ì í•©ì„±ì„ ë°˜ì˜í•  ë•Œ ì±„íƒì´ ì´‰ì§„ëœë‹¤.",
    "ì˜ˆì¸¡ ì¤‘ì‹¬ ì§ë¬´êµ°ì€ â€˜ìœ„ì„ ì „ëµâ€™ì´ ê¸°ë³¸ ì›ì¹™ì´ì–´ì•¼ í•œë‹¤.",
    "ê³µê° ì¤‘ì‹¬ ì§ë¬´êµ°ì€ â€˜í˜‘ì—… ì „ëµâ€™ì´ ê¸°ë³¸ ì›ì¹™ì´ì–´ì•¼ í•œë‹¤.",
    "ê³ ê°ì„¼í„°ì—ì„œëŠ” AI ì´ˆì•ˆ+ì¸ê°„ ìµœì¢… ê²€ìˆ˜(í•˜ì´ë¸Œë¦¬ë“œ)ê°€ ë¹„ìš©ê³¼ ë§Œì¡±ë„ë¥¼ ë™ì‹œì— ê°œì„ í•œë‹¤.",
    "ì˜ë£Œì—ì„œëŠ” ê³µê°í˜• ì´ˆì§„Â·ì„¤ëª… + ì˜ì‚¬ íŒë‹¨ ê²°í•©ì´ ì•ˆì „ì„±ê³¼ ì‹ ë¢°ë¥¼ ë³´ì¥í•œë‹¤.",
    "êµìœ¡ì—ì„œëŠ” AIì˜ ê°œë³„ í”¼ë“œë°± + êµì‚¬ì˜ ì •ì„œ ì½”ì¹­ì´ í•™ìŠµ ì§€ì†ì„±ì„ ë†’ì¸ë‹¤.",
    "ì‚¬ìš©ì ì„¸ë¶„í™”(ë„êµ¬ì§€í–¥/ê´€ê³„ì§€í–¥)ì— ë”°ë¼ í†¤ê³¼ ìë™í™” ìˆ˜ì¤€ì„ ì°¨ë“± ì œê³µí•´ì•¼ í•œë‹¤.",
]
Q_COLS = [f"Q{i:02d}" for i in range(1, len(Q_SET)+1)]
LIKERT = ["ì „í˜€ ë™ì˜í•˜ì§€ ì•ŠìŒ(1)", "ë™ì˜í•˜ì§€ ì•ŠìŒ(2)", "ë³´í†µ(3)", "ë™ì˜í•¨(4)", "ë§¤ìš° ë™ì˜í•¨(5)"]
LIKERT_MAP = {"ì „í˜€ ë™ì˜í•˜ì§€ ì•ŠìŒ(1)":1,"ë™ì˜í•˜ì§€ ì•ŠìŒ(2)":2,"ë³´í†µ(3)":3,"ë™ì˜í•¨(4)":4,"ë§¤ìš° ë™ì˜í•¨(5)":5}

# -----------------------------
# Tabs
# -----------------------------
tab1, tab2, tab3 = st.tabs(["âœï¸ ì„¤ë¬¸ ìˆ˜ì§‘(ì´ë©”ì¼ í•„ìˆ˜)", "ğŸ“Š ì‚¬ëŒ ìš”ì¸í™”(Q) ë¶„ì„", "â˜ï¸ GitHub ë™ê¸°í™” ë¡œê·¸"])

# -----------------------------
# Tab1: Survey
# -----------------------------
with tab1:
    st.subheader("ì‘ë‹µ ì…ë ¥ (ì´ë©”ì¼ í•„ìˆ˜)")
    email = st.text_input("ì´ë©”ì¼(í•„ìˆ˜) â€” í›„ì† íŒ¨ë„ ì¡°ì‚¬/ë³´ìƒ ì•ˆë‚´ìš©")
    with st.form("likert_form"):
        answers = {}
        for i, stmt in enumerate(Q_SET, start=1):
            qid = f"Q{i:02d}"
            sel = st.radio(f"{i}. {stmt}", LIKERT, horizontal=True, key=f"r_{qid}")
            answers[qid] = LIKERT_MAP[sel]
        submitted = st.form_submit_button("ì œì¶œ")

    if submitted:
        if not is_valid_email(email):
            st.error("ì˜¬ë°”ë¥¸ ì´ë©”ì¼ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”. (ì˜ˆ: name@example.com)")
        else:
            try:
                row = {**answers, "email": email.strip(), "ts": datetime.datetime.now().isoformat()}
                file_exists = os.path.exists(DATA_PATH)
                file_empty  = file_exists and os.path.getsize(DATA_PATH) == 0

                df_old = load_csv_safe(DATA_PATH)
                if df_old is None:
                    df_all = pd.DataFrame([row])
                else:
                    df_old, _ = ensure_q_columns(df_old, q_count=len(Q_SET))
                    df_all = pd.concat([df_old, pd.DataFrame([row])], ignore_index=True)

                if save_csv_safe(df_all, DATA_PATH):
                    msg = "ì‘ë‹µì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤. "
                    if file_exists and file_empty: msg += "(ë¹ˆ íŒŒì¼ì— ì²« ì‘ë‹µ ê¸°ë¡)"
                    st.success(msg)

                    # ğŸ” GitHub ìë™ ë™ê¸°í™”
                    if auto_sync:
                        ok, resp = push_csv_to_github(DATA_PATH, GH_REMOTEP,
                                                      note=f"Update {GH_REMOTEP} at {datetime.datetime.now().isoformat()}")
                        if ok:
                            st.success("GitHubì— ë™ê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        else:
                            st.warning(f"GitHub ë™ê¸°í™” ì‹¤íŒ¨: {resp}")
                    else:
                        st.info("ìë™ ë™ê¸°í™”ê°€ êº¼ì ¸ ìˆìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ 'ì§€ê¸ˆ ë™ê¸°í™”'ë¥¼ ëˆ„ë¥´ì„¸ìš”.")
            except Exception as e:
                st.error(f"ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

# -----------------------------
# Person-Q Analysis Helpers
# -----------------------------
def person_q_analysis(df_q: pd.DataFrame,
                      corr_metric: str = "Pearson",
                      n_factors: int | None = None,
                      rotate: bool = True):
    M = df_q.values.astype(float)
    if corr_metric.lower().startswith("spear"):
        M_proc = rank_rows(M)
        M_proc = zscore_rows(M_proc)
    else:
        M_proc = zscore_rows(M)

    R = np.corrcoef(M_proc, rowvar=True)
    R = np.nan_to_num(R, nan=0.0, posinf=0.0, neginf=0.0)

    eigvals, eigvecs = np.linalg.eigh(R)
    idx = np.argsort(eigvals)[::-1]
    eigvals = eigvals[idx]; eigvecs = eigvecs[:, idx]

    nmax = max(2, min(6, R.shape[0]-1))
    if n_factors is None or n_factors < 1:
        n_factors = choose_n_factors(eigvals, nmax)
    else:
        n_factors = max(2, min(nmax, int(n_factors)))

    L = eigvecs[:, :n_factors] * np.sqrt(np.maximum(eigvals[:n_factors], 0))
    L_rot = varimax(L)[0] if rotate else L

    arrays = []
    for k in range(n_factors):
        w = np.clip(L_rot[:, k], a_min=0.0, a_max=None)
        if w.sum() <= EPS: w = np.abs(L_rot[:, k])
        w = w / (w.sum() + EPS)
        arr_k = w @ M_proc
        arrays.append(arr_k)
    arrays = np.vstack(arrays)
    return L_rot, eigvals, R, arrays

def assign_types(loadings: np.ndarray, emails: list[str], thr: float = 0.40, sep: float = 0.10):
    N, K = loadings.shape
    max_idx = loadings.argmax(axis=1)
    max_val = loadings.max(axis=1)
    sorted_vals = np.sort(loadings, axis=1)[:, ::-1]
    second = sorted_vals[:,1] if K >= 2 else np.zeros(N)
    assigned = (max_val >= thr) & ((max_val - second) >= sep)
    rows = []
    for i in range(N):
        rows.append({
            "email": emails[i] if i < len(emails) else f"id_{i}",
            "Type": f"Type{max_idx[i]+1}",
            "MaxLoading": float(max_val[i]),
            "Second": float(second[i]),
            "Assigned": bool(assigned[i])
        })
    return pd.DataFrame(rows)

def top_bottom_statements(factor_arrays: np.ndarray, topk=5):
    K, P = factor_arrays.shape
    tb = []
    for k in range(K):
        z = factor_arrays[k]
        top_idx = np.argsort(z)[::-1][:topk]
        bot_idx = np.argsort(z)[:topk]
        tb.append((top_idx, bot_idx, z))
    return tb

# -----------------------------
# Tab2: Person-Q Analysis
# -----------------------------
with tab2:
    st.subheader("ì‚¬ëŒ ìš”ì¸í™”(Q) ë¶„ì„")
    df = load_csv_safe(DATA_PATH)
    if df is None:
        st.info("ì•„ì§ ìˆ˜ì§‘ëœ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤. (ë¹ˆ íŒŒì¼ì´ë©´ ë¨¼ì € ì„¤ë¬¸ ì œì¶œ)")
    else:
        df, _ = ensure_q_columns(df, q_count=len(Q_SET))
        df_q = df[Q_COLS].copy()
        mask = df_q.notna().sum(axis=1) >= int(0.6*len(Q_COLS))
        df_q = df_q[mask]
        emails = df.loc[mask, "email"].fillna("").astype(str).tolist()

        st.write(f"ìœ íš¨ ì‘ë‹µì ìˆ˜: **{len(df_q)}ëª…**")
        if len(df_q) < MIN_N_FOR_ANALYSIS:
            st.warning(f"ë¶„ì„ì—ëŠ” ìµœì†Œ {MIN_N_FOR_ANALYSIS}ëª…ì˜ ì‘ë‹µì´ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            with st.expander("âš™ï¸ ë¶„ì„ ì˜µì…˜", expanded=True):
                colA, colB, colC = st.columns(3)
                with colA:
                    corr_metric = st.selectbox("ìƒê´€ê³„ìˆ˜", ["Pearson", "Spearman"], index=0)
                with colB:
                    n_f_override = st.number_input("ìš”ì¸ ìˆ˜(ì„ íƒ, 0=ìë™)", min_value=0, max_value=6, value=0, step=1)
                    n_factors = None if n_f_override == 0 else int(n_f_override)
                with colC:
                    rotate = st.checkbox("Varimax íšŒì „", value=True)

                thr = st.slider("ìœ í˜• ë°°ì • ì„ê³„ê°’(ìµœëŒ€ ì ì¬ì¹˜)", 0.20, 0.70, 0.40, 0.05)
                sep = st.slider("1ë“±-2ë“± ì ì¬ì¹˜ ìµœì†Œ ê²©ì°¨", 0.00, 0.50, 0.10, 0.05)

            try:
                loadings, eigvals, R, arrays = person_q_analysis(df_q, corr_metric, n_factors, rotate)
                K = loadings.shape[1]

                st.markdown(f"**ì¶”ì¶œ ìš”ì¸ ìˆ˜: {K}**")
                load_df = pd.DataFrame(loadings, columns=[f"Type{i+1}" for i in range(K)])
                load_df.insert(0, "email", emails)
                st.dataframe(load_df.style.background_gradient(cmap="Blues", axis=None), use_container_width=True)

                assign_df = assign_types(loadings, emails, thr=thr, sep=sep)
                st.markdown("### ì°¸ê°€ì ìœ í˜• ë°°ì •")
                st.dataframe(assign_df, use_container_width=True)
                st.write("ìœ í˜•ë³„ ì¸ì›ìˆ˜:", assign_df[assign_df["Assigned"]].groupby("Type").size().to_dict())

                st.download_button(
                    "ğŸ“¥ ì°¸ê°€ì-ìœ í˜• ë°°ì • CSV",
                    data=assign_df.to_csv(index=False).encode("utf-8-sig"),
                    file_name="person_type_assignments.csv",
                    mime="text/csv"
                )

                arrays_df = pd.DataFrame(arrays, columns=Q_COLS, index=[f"Type{i+1}" for i in range(K)])
                st.markdown("### ìœ í˜•ë³„ factor array (ì§„ìˆ  z-í”„ë¡œíŒŒì¼)")
                st.dataframe(arrays_df, use_container_width=True)
                st.download_button(
                    "ğŸ“¥ ìœ í˜•ë³„ factor array CSV",
                    data=arrays_df.to_csv().encode("utf-8-sig"),
                    file_name="type_factor_arrays.csv",
                    mime="text/csv"
                )

                st.markdown(f"### ìœ í˜•ë³„ ìƒ/í•˜ìœ„ ì§„ìˆ  Top {TOPK_STATEMENTS}")
                tb = top_bottom_statements(arrays, topk=TOPK_STATEMENTS)
                for i, (top_idx, bot_idx, z) in enumerate(tb, start=1):
                    with st.expander(f"Type{i} ìƒ/í•˜ìœ„ ì§„ìˆ ", expanded=True if i==1 else False):
                        st.markdown("**ìƒìœ„(+) ì§„ìˆ **")
                        for j in top_idx:
                            st.write(f"- Q{j+1:02d} (z={z[j]:.2f}) : {Q_SET[j]}")
                        st.markdown("**í•˜ìœ„(âˆ’) ì§„ìˆ **")
                        for j in bot_idx:
                            st.write(f"- Q{j+1:02d} (z={z[j]:.2f}) : {Q_SET[j]}")

            except Exception as e:
                st.error(f"ì‚¬ëŒ ìš”ì¸í™” ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")

# -----------------------------
# Tab3: GitHub Sync Log / Manual Push
# -----------------------------
with tab3:
    st.subheader("GitHub ë™ê¸°í™”")
    if not (GH_TOKEN and GH_REPO):
        st.warning("Secretsì— github.token, github.repo ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        st.code("""
[github]
token = "ghp_..."
repo  = "owner/repo"
branch = "main"
data_path = "data/responses_tadt.csv"
        """, language="toml")
    else:
        st.success(f"ì›ê²©: {GH_REPO} @ {GH_BRANCH}\nê²½ë¡œ: {GH_REMOTEP}")

    if st.button("ì§€ê¸ˆ ë™ê¸°í™”(ìˆ˜ë™)"):
        if os.path.exists(DATA_PATH) and os.path.getsize(DATA_PATH) > 0:
            ok, resp = push_csv_to_github(DATA_PATH, GH_REMOTEP,
                                          note=f"Manual sync {GH_REMOTEP} at {datetime.datetime.now().isoformat()}")
            if ok:
                st.success("GitHubì— ë™ê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.json(resp)
            else:
                st.error(f"ë™ê¸°í™” ì‹¤íŒ¨: {resp}")
        else:
            st.error("ë¡œì»¬ CSVê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë¨¼ì € ì„¤ë¬¸ì„ ì œì¶œí•´ CSVë¥¼ ìƒì„±í•˜ì„¸ìš”.")
